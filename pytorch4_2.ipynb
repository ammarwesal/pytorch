{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO9ZLEj8WaLGT17K33luluI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ammarwesal/pytorch/blob/main/pytorch4_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###prediction:MANUALLY\n",
        "###gradienT_computation:Autograd\n",
        "###loss_computation:MANUALLY\n",
        "###parameter_updates:MANUALLY"
      ],
      "metadata": {
        "id": "lKG3djNtzErh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6_aMIyMy_lU",
        "outputId": "370dc493-6b7b-4ae2-af9a-471b3f668914"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prediction before training: f(5)=0.000\n",
            "epoch 1: w=0.300, loss=30.00000000\n",
            "prediction after training: f(5)=1.500\n",
            "epoch 2: w=0.555, loss=21.67499924\n",
            "prediction after training: f(5)=2.775\n",
            "epoch 3: w=0.772, loss=15.66018772\n",
            "prediction after training: f(5)=3.859\n",
            "epoch 4: w=0.956, loss=11.31448650\n",
            "prediction after training: f(5)=4.780\n",
            "epoch 5: w=1.113, loss=8.17471695\n",
            "prediction after training: f(5)=5.563\n",
            "epoch 6: w=1.246, loss=5.90623236\n",
            "prediction after training: f(5)=6.229\n",
            "epoch 7: w=1.359, loss=4.26725292\n",
            "prediction after training: f(5)=6.794\n",
            "epoch 8: w=1.455, loss=3.08308983\n",
            "prediction after training: f(5)=7.275\n",
            "epoch 9: w=1.537, loss=2.22753215\n",
            "prediction after training: f(5)=7.684\n",
            "epoch 10: w=1.606, loss=1.60939169\n",
            "prediction after training: f(5)=8.031\n",
            "epoch 11: w=1.665, loss=1.16278565\n",
            "prediction after training: f(5)=8.327\n",
            "epoch 12: w=1.716, loss=0.84011245\n",
            "prediction after training: f(5)=8.578\n",
            "epoch 13: w=1.758, loss=0.60698116\n",
            "prediction after training: f(5)=8.791\n",
            "epoch 14: w=1.794, loss=0.43854395\n",
            "prediction after training: f(5)=8.972\n",
            "epoch 15: w=1.825, loss=0.31684780\n",
            "prediction after training: f(5)=9.126\n",
            "epoch 16: w=1.851, loss=0.22892261\n",
            "prediction after training: f(5)=9.257\n",
            "epoch 17: w=1.874, loss=0.16539653\n",
            "prediction after training: f(5)=9.369\n",
            "epoch 18: w=1.893, loss=0.11949898\n",
            "prediction after training: f(5)=9.464\n",
            "epoch 19: w=1.909, loss=0.08633806\n",
            "prediction after training: f(5)=9.544\n",
            "epoch 20: w=1.922, loss=0.06237914\n",
            "prediction after training: f(5)=9.612\n",
            "epoch 21: w=1.934, loss=0.04506890\n",
            "prediction after training: f(5)=9.671\n",
            "epoch 22: w=1.944, loss=0.03256231\n",
            "prediction after training: f(5)=9.720\n",
            "epoch 23: w=1.952, loss=0.02352631\n",
            "prediction after training: f(5)=9.762\n",
            "epoch 24: w=1.960, loss=0.01699772\n",
            "prediction after training: f(5)=9.798\n",
            "epoch 25: w=1.966, loss=0.01228084\n",
            "prediction after training: f(5)=9.828\n",
            "epoch 26: w=1.971, loss=0.00887291\n",
            "prediction after training: f(5)=9.854\n",
            "epoch 27: w=1.975, loss=0.00641066\n",
            "prediction after training: f(5)=9.876\n",
            "epoch 28: w=1.979, loss=0.00463169\n",
            "prediction after training: f(5)=9.894\n",
            "epoch 29: w=1.982, loss=0.00334642\n",
            "prediction after training: f(5)=9.910\n",
            "epoch 30: w=1.985, loss=0.00241778\n",
            "prediction after training: f(5)=9.924\n",
            "epoch 31: w=1.987, loss=0.00174685\n",
            "prediction after training: f(5)=9.935\n",
            "epoch 32: w=1.989, loss=0.00126211\n",
            "prediction after training: f(5)=9.945\n",
            "epoch 33: w=1.991, loss=0.00091188\n",
            "prediction after training: f(5)=9.953\n",
            "epoch 34: w=1.992, loss=0.00065882\n",
            "prediction after training: f(5)=9.960\n",
            "epoch 35: w=1.993, loss=0.00047601\n",
            "prediction after training: f(5)=9.966\n",
            "epoch 36: w=1.994, loss=0.00034392\n",
            "prediction after training: f(5)=9.971\n",
            "epoch 37: w=1.995, loss=0.00024848\n",
            "prediction after training: f(5)=9.976\n",
            "epoch 38: w=1.996, loss=0.00017952\n",
            "prediction after training: f(5)=9.979\n",
            "epoch 39: w=1.996, loss=0.00012971\n",
            "prediction after training: f(5)=9.982\n",
            "epoch 40: w=1.997, loss=0.00009371\n",
            "prediction after training: f(5)=9.985\n",
            "epoch 41: w=1.997, loss=0.00006770\n",
            "prediction after training: f(5)=9.987\n",
            "epoch 42: w=1.998, loss=0.00004891\n",
            "prediction after training: f(5)=9.989\n",
            "epoch 43: w=1.998, loss=0.00003534\n",
            "prediction after training: f(5)=9.991\n",
            "epoch 44: w=1.998, loss=0.00002553\n",
            "prediction after training: f(5)=9.992\n",
            "epoch 45: w=1.999, loss=0.00001845\n",
            "prediction after training: f(5)=9.993\n",
            "epoch 46: w=1.999, loss=0.00001333\n",
            "prediction after training: f(5)=9.994\n",
            "epoch 47: w=1.999, loss=0.00000963\n",
            "prediction after training: f(5)=9.995\n",
            "epoch 48: w=1.999, loss=0.00000696\n",
            "prediction after training: f(5)=9.996\n",
            "epoch 49: w=1.999, loss=0.00000503\n",
            "prediction after training: f(5)=9.997\n",
            "epoch 50: w=1.999, loss=0.00000363\n",
            "prediction after training: f(5)=9.997\n",
            "epoch 51: w=1.999, loss=0.00000262\n",
            "prediction after training: f(5)=9.997\n",
            "epoch 52: w=2.000, loss=0.00000190\n",
            "prediction after training: f(5)=9.998\n",
            "epoch 53: w=2.000, loss=0.00000137\n",
            "prediction after training: f(5)=9.998\n",
            "epoch 54: w=2.000, loss=0.00000099\n",
            "prediction after training: f(5)=9.998\n",
            "epoch 55: w=2.000, loss=0.00000071\n",
            "prediction after training: f(5)=9.999\n",
            "epoch 56: w=2.000, loss=0.00000052\n",
            "prediction after training: f(5)=9.999\n",
            "epoch 57: w=2.000, loss=0.00000037\n",
            "prediction after training: f(5)=9.999\n",
            "epoch 58: w=2.000, loss=0.00000027\n",
            "prediction after training: f(5)=9.999\n",
            "epoch 59: w=2.000, loss=0.00000019\n",
            "prediction after training: f(5)=9.999\n",
            "epoch 60: w=2.000, loss=0.00000014\n",
            "prediction after training: f(5)=9.999\n",
            "epoch 61: w=2.000, loss=0.00000010\n",
            "prediction after training: f(5)=10.000\n",
            "epoch 62: w=2.000, loss=0.00000007\n",
            "prediction after training: f(5)=10.000\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "#f=w*x\n",
        "\n",
        "#f=2*x\n",
        "X=torch.tensor([1,2,3,4],dtype=torch.float32)\n",
        "y=torch.tensor([2,4,6,8],dtype=torch.float32)\n",
        "\n",
        "w=torch.tensor(0.0,dtype=torch.float32, requires_grad=True)\n",
        "\n",
        "#model prediction\n",
        "def forward(X):\n",
        "  return w*X\n",
        "\n",
        "#loss=MSE\n",
        "def loss(y,y_predicted):\n",
        "  return ((y_predicted-y)**2).mean()\n",
        "\n",
        "\n",
        "print(f'prediction before training: f(5)={forward(5):.3f}')\n",
        "\n",
        "#training\n",
        "learning_rate=0.01\n",
        "n_iters=62\n",
        "\n",
        "for epoch in range(n_iters):\n",
        "  #prediction=forward pass\n",
        "  y_pred=forward(X)\n",
        "\n",
        "  #loss\n",
        "  l=loss(y,y_pred)\n",
        "\n",
        "  #gradient=backward pass\n",
        "  l.backward()#dL/dw\n",
        "\n",
        "  #update weights\n",
        "  with torch.no_grad():\n",
        "     w-=learning_rate*w.grad\n",
        "\n",
        "  #zero gradients\n",
        "  w.grad.zero_()\n",
        "\n",
        "  if epoch%1==0:\n",
        "    print(f'epoch {epoch+1}: w={w:.3f}, loss={l:.8f}')\n",
        "\n",
        "  print(f'prediction after training: f(5)={forward(5):.3f}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_xc-1yjgzeQs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}